{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sb3_contrib.common.maskable.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from CustomEncoder import CustomCombinedExtractor\n",
    "from wandb.integration.sb3 import WandbCallback\n",
    "from sb3_contrib.ppo_mask import MaskablePPO\n",
    "from benchmark import get_benchmarking_data\n",
    "from env import MPSPEnv\n",
    "import numpy as np\n",
    "import torch\n",
    "import wandb\n",
    "import os\n",
    "os.environ['WANDB_NOTEBOOK_NAME'] = 'sb3.ipynb'\n",
    "os.environ[\"WANDB_SILENT\"] = 'true'\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    # Environment\n",
    "    'ROWS': 6,\n",
    "    'COLUMNS': 2,\n",
    "    'N_PORTS': 4,\n",
    "    # Model\n",
    "    'EMBEDDING_SIZE': 10,\n",
    "    'PI_LAYER_SIZES': [256, 512, 256],\n",
    "    'VF_LAYER_SIZES': [256, 512, 256],\n",
    "    # Training\n",
    "    'TOTAL_TIMESTEPS': 1000,\n",
    "    'START_LEARNING_RATE': 0.00007,\n",
    "    'END_LEARNING_RATE': 0.000004,\n",
    "    'BATCH_SIZE': 128\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = wandb.init(\n",
    "    project=\"PPO-SB3\",\n",
    "    entity=\"rl-msps\",\n",
    "    sync_tensorboard=True,\n",
    "    name=f\"N{config['N_PORTS']}_R{config['ROWS']}_C{config['COLUMNS']}\",\n",
    "    config=config,\n",
    "    tags=[\"test\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = MPSPEnv(\n",
    "    config['ROWS'],\n",
    "    config['COLUMNS'],\n",
    "    config['N_PORTS']\n",
    ")\n",
    "env = Monitor(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def linear_schedule(start, end):\n",
    "#     \"\"\"\n",
    "#     Linear learning rate schedule.\n",
    "\n",
    "#     :param initial_value: Initial learning rate.\n",
    "#     :return: schedule that computes\n",
    "#       current learning rate depending on remaining progress\n",
    "#     \"\"\"\n",
    "\n",
    "#     def func(progress_remaining: float) -> float:\n",
    "#         \"\"\"\n",
    "#         Progress will decrease from 1 (beginning) to 0.\n",
    "\n",
    "#         :param progress_remaining:\n",
    "#         :return: current learning rate\n",
    "#         \"\"\"\n",
    "#         return start + progress_remaining * (end - start)\n",
    "\n",
    "#     return func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy_kwargs = {\n",
    "    'activation_fn': torch.nn.ReLU,\n",
    "    'net_arch': [{\n",
    "        'pi': config['PI_LAYER_SIZES'],\n",
    "        'vf': config['VF_LAYER_SIZES']\n",
    "    }],\n",
    "    # 'features_extractor_class': CustomCombinedExtractor,\n",
    "    # 'features_extractor_kwargs': {\n",
    "    #     'n_ports': config['N_PORTS'],\n",
    "    #     'embedding_size': config['EMBEDDING_SIZE']\n",
    "    # }\n",
    "}\n",
    "\n",
    "model = MaskablePPO(\n",
    "    policy='MultiInputPolicy',\n",
    "    env=env,\n",
    "    batch_size=config['BATCH_SIZE'],\n",
    "    verbose=0,\n",
    "    tensorboard_log=f\"runs/{run.id}\",\n",
    "    policy_kwargs=policy_kwargs,\n",
    "    # learning_rate=linear_schedule(\n",
    "    #     start=config['START_LEARNING_RATE'],\n",
    "    #     end=config['END_LEARNING_RATE']\n",
    "    # )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.learn(\n",
    "    total_timesteps=config['TOTAL_TIMESTEPS'],\n",
    "    callback=WandbCallback(\n",
    "        model_save_path=f\"models/{run.id}\",\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval = evaluate_policy(\n",
    "    model,\n",
    "    env,\n",
    "    n_eval_episodes=1000\n",
    ")\n",
    "eval = {\n",
    "    'mean_reward': eval[0],\n",
    "    'std_reward': eval[1]\n",
    "}\n",
    "run.summary['evaluation'] = eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_data = get_benchmarking_data('rl-mpsp-benchmark/set_2')\n",
    "eval_data = [\n",
    "    e for e in eval_data if (\n",
    "        e['R'] == config['ROWS'] and\n",
    "        e['C'] == config['COLUMNS'] and\n",
    "        e['N'] == config['N_PORTS']\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run over eval_data and evaluate the model\n",
    "eval_rewards = []\n",
    "# Negative because env returns negative reward for shifts\n",
    "paper_rewards = [-e['paper_result'] for e in eval_data]\n",
    "paper_seeds = [e['seed'] for e in eval_data]\n",
    "\n",
    "for e in eval_data:\n",
    "    total_reward = 0\n",
    "    obs = env.reset(\n",
    "        transportation_matrix=e['transportation_matrix']\n",
    "    )\n",
    "    done = False\n",
    "    while not done:\n",
    "        action, _ = model.predict(\n",
    "            obs,\n",
    "            action_masks=env.action_masks()\n",
    "        )\n",
    "        obs, reward, done, _ = env.step(action)\n",
    "        total_reward += reward\n",
    "\n",
    "    eval_rewards.append(total_reward)\n",
    "\n",
    "eval = {\n",
    "    'mean_reward': np.mean(eval_rewards),\n",
    "    'mean_paper_reward': np.mean(paper_rewards),\n",
    "    'rewards': eval_rewards,\n",
    "    'paper_rewards': paper_rewards,\n",
    "    'paper_seeds': paper_seeds\n",
    "}\n",
    "run.summary['evaluation_benchmark'] = eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "59669bb1168edc622bb4dae0f982b2741a2a7b3cacb44a90a5e1c2622e59ac77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
